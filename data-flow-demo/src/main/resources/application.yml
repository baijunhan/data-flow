#spring:
#  kafka:
#    consumer:
#      bootstrap-servers: 10.40.75.137:9092,10.40.14.11:9092,10.40.14.12:9092
#      group-id: ${core.system.kafka.topic}
#      enable-auto-commit: false
#      auto-commit-interval: 1000ms
#      auto-offset-reset: earliest
#      max-poll-records: 20
#      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      value-deserializer: net.wecash.coresystem.net.wecash.abakuscoresystem.data.canal.CanalMessageDeserializer
#    listener:
#      ack-mode: manual
#
logging:
  config: classpath:logback-spring-${spring.profiles.active}.xml

server:
  port: 8081
  servlet:
    context-path: /event
management:
  endpoint:
    health:
      show-details: always
  endpoints:
    web:
      exposure:
        include: '*'
  server:
    port: ${server.port}
    servlet:
      context-path: ${server.servlet.context-path}
canal:
  listen-table-config:
    # 需要监听处理数据库中的表, 表名可用正则表达式
    - schema: (?i)abak
      tables:
        - (?i)lm_loan
        - (?i)lm_pm_shd
        - (?i)lm_setlmt_log
spring:
  servlet:
    multipart:
      max-file-size: 1GB
      max-request-size: 1GB
  kafka:
    bootstrap-servers: ubuntu:9092
    listener:
      ack-mode: manual
      concurrency: 1
    consumer:
      group-id: test
data-flow:
  enable: true
multi-data-source:
  enable: true